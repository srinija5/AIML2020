{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # <span style=\"color:green\">          KNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Problem Statement**\n",
    "\n",
    "The problem that we are going to solve here is that given a set of features that describe a tumour whether it is Malignant or Benign, our machine learning model must predict whether the tumour is Malignant or Benign. To train our machine learning model with tumour data, we will be using [SCLCData](https://raw.githubusercontent.com/Mounika-Kajjam/Datasets/master/wbcd.csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\srinaja\\miniconda3\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.9.3 in c:\\users\\srinaja\\miniconda3\\lib\\site-packages (from seaborn) (1.17.2)\n",
      "Requirement already satisfied: pandas>=0.15.2 in c:\\users\\srinaja\\miniconda3\\lib\\site-packages (from seaborn) (0.25.1)\n",
      "Requirement already satisfied: scipy>=0.14.0 in c:\\users\\srinaja\\miniconda3\\lib\\site-packages (from seaborn) (1.4.1)\n",
      "Requirement already satisfied: matplotlib>=1.4.3 in c:\\users\\srinaja\\miniconda3\\lib\\site-packages (from seaborn) (3.2.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\srinaja\\miniconda3\\lib\\site-packages (from pandas>=0.15.2->seaborn) (2019.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\srinaja\\miniconda3\\lib\\site-packages (from pandas>=0.15.2->seaborn) (2.8.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\srinaja\\miniconda3\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (2.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\srinaja\\miniconda3\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\srinaja\\miniconda3\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\srinaja\\miniconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas>=0.15.2->seaborn) (1.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\srinaja\\miniconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn) (41.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\srinaja\\miniconda3\\lib\\site-packages (3.2.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\srinaja\\miniconda3\\lib\\site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.11 in c:\\users\\srinaja\\miniconda3\\lib\\site-packages (from matplotlib) (1.17.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\srinaja\\miniconda3\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\srinaja\\miniconda3\\lib\\site-packages (from matplotlib) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\srinaja\\miniconda3\\lib\\site-packages (from matplotlib) (2.8.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\srinaja\\miniconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib) (41.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\srinaja\\miniconda3\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>87139402</td>\n",
       "      <td>B</td>\n",
       "      <td>12.32</td>\n",
       "      <td>12.39</td>\n",
       "      <td>78.85</td>\n",
       "      <td>464.1</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>0.06981</td>\n",
       "      <td>0.03987</td>\n",
       "      <td>0.03700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.50</td>\n",
       "      <td>15.64</td>\n",
       "      <td>86.97</td>\n",
       "      <td>549.1</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.12420</td>\n",
       "      <td>0.09391</td>\n",
       "      <td>0.2827</td>\n",
       "      <td>0.06771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8910251</td>\n",
       "      <td>B</td>\n",
       "      <td>10.60</td>\n",
       "      <td>18.95</td>\n",
       "      <td>69.28</td>\n",
       "      <td>346.4</td>\n",
       "      <td>0.09688</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>0.06387</td>\n",
       "      <td>0.02642</td>\n",
       "      <td>...</td>\n",
       "      <td>11.88</td>\n",
       "      <td>22.94</td>\n",
       "      <td>78.28</td>\n",
       "      <td>424.8</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.19160</td>\n",
       "      <td>0.07926</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.07587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>905520</td>\n",
       "      <td>B</td>\n",
       "      <td>11.04</td>\n",
       "      <td>16.83</td>\n",
       "      <td>70.92</td>\n",
       "      <td>373.2</td>\n",
       "      <td>0.10770</td>\n",
       "      <td>0.07804</td>\n",
       "      <td>0.03046</td>\n",
       "      <td>0.02480</td>\n",
       "      <td>...</td>\n",
       "      <td>12.41</td>\n",
       "      <td>26.44</td>\n",
       "      <td>79.93</td>\n",
       "      <td>471.4</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.10670</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.2998</td>\n",
       "      <td>0.07881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>868871</td>\n",
       "      <td>B</td>\n",
       "      <td>11.28</td>\n",
       "      <td>13.39</td>\n",
       "      <td>73.00</td>\n",
       "      <td>384.8</td>\n",
       "      <td>0.11640</td>\n",
       "      <td>0.11360</td>\n",
       "      <td>0.04635</td>\n",
       "      <td>0.04796</td>\n",
       "      <td>...</td>\n",
       "      <td>11.92</td>\n",
       "      <td>15.77</td>\n",
       "      <td>76.53</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>0.1822</td>\n",
       "      <td>0.08669</td>\n",
       "      <td>0.08611</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.06784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9012568</td>\n",
       "      <td>B</td>\n",
       "      <td>15.19</td>\n",
       "      <td>13.21</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.8</td>\n",
       "      <td>0.07963</td>\n",
       "      <td>0.06934</td>\n",
       "      <td>0.03393</td>\n",
       "      <td>0.02657</td>\n",
       "      <td>...</td>\n",
       "      <td>16.20</td>\n",
       "      <td>15.73</td>\n",
       "      <td>104.50</td>\n",
       "      <td>819.1</td>\n",
       "      <td>0.1126</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.13620</td>\n",
       "      <td>0.08178</td>\n",
       "      <td>0.2487</td>\n",
       "      <td>0.06766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0  87139402         B        12.32         12.39           78.85      464.1   \n",
       "1   8910251         B        10.60         18.95           69.28      346.4   \n",
       "2    905520         B        11.04         16.83           70.92      373.2   \n",
       "3    868871         B        11.28         13.39           73.00      384.8   \n",
       "4   9012568         B        15.19         13.21           97.65      711.8   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  points_mean  ...  \\\n",
       "0          0.10280           0.06981         0.03987      0.03700  ...   \n",
       "1          0.09688           0.11470         0.06387      0.02642  ...   \n",
       "2          0.10770           0.07804         0.03046      0.02480  ...   \n",
       "3          0.11640           0.11360         0.04635      0.04796  ...   \n",
       "4          0.07963           0.06934         0.03393      0.02657  ...   \n",
       "\n",
       "   radius_worst  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0         13.50          15.64            86.97       549.1            0.1385   \n",
       "1         11.88          22.94            78.28       424.8            0.1213   \n",
       "2         12.41          26.44            79.93       471.4            0.1369   \n",
       "3         11.92          15.77            76.53       434.0            0.1367   \n",
       "4         16.20          15.73           104.50       819.1            0.1126   \n",
       "\n",
       "   compactness_worst  concavity_worst  points_worst  symmetry_worst  \\\n",
       "0             0.1266          0.12420       0.09391          0.2827   \n",
       "1             0.2515          0.19160       0.07926          0.2940   \n",
       "2             0.1482          0.10670       0.07431          0.2998   \n",
       "3             0.1822          0.08669       0.08611          0.2102   \n",
       "4             0.1737          0.13620       0.08178          0.2487   \n",
       "\n",
       "   dimension_worst  \n",
       "0          0.06771  \n",
       "1          0.07587  \n",
       "2          0.07881  \n",
       "3          0.06784  \n",
       "4          0.06766  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the data\n",
    "data =pd.read_csv(\"https://raw.githubusercontent.com/Mounika-Kajjam/Datasets/master/wbcd.csv\",sep=\",\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for no of rows and columns\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    357\n",
       "M    212\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the frequency of B and M\n",
    "data.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "diagnosis            0\n",
       "radius_mean          0\n",
       "texture_mean         0\n",
       "perimeter_mean       0\n",
       "area_mean            0\n",
       "smoothness_mean      0\n",
       "compactness_mean     0\n",
       "concavity_mean       0\n",
       "points_mean          0\n",
       "symmetry_mean        0\n",
       "dimension_mean       0\n",
       "radius_se            0\n",
       "texture_se           0\n",
       "perimeter_se         0\n",
       "area_se              0\n",
       "smoothness_se        0\n",
       "compactness_se       0\n",
       "concavity_se         0\n",
       "points_se            0\n",
       "symmetry_se          0\n",
       "dimension_se         0\n",
       "radius_worst         0\n",
       "texture_worst        0\n",
       "perimeter_worst      0\n",
       "area_worst           0\n",
       "smoothness_worst     0\n",
       "compactness_worst    0\n",
       "concavity_worst      0\n",
       "points_worst         0\n",
       "symmetry_worst       0\n",
       "dimension_worst      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking null values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>3.037183e+07</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.250206e+08</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>8.692180e+05</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>9.060240e+05</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>8.813129e+06</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count  5.690000e+02   569.000000    569.000000      569.000000   569.000000   \n",
       "mean   3.037183e+07    14.127292     19.289649       91.969033   654.889104   \n",
       "std    1.250206e+08     3.524049      4.301036       24.298981   351.914129   \n",
       "min    8.670000e+03     6.981000      9.710000       43.790000   143.500000   \n",
       "25%    8.692180e+05    11.700000     16.170000       75.170000   420.300000   \n",
       "50%    9.060240e+05    13.370000     18.840000       86.240000   551.100000   \n",
       "75%    8.813129e+06    15.780000     21.800000      104.100000   782.700000   \n",
       "max    9.113205e+08    28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  points_mean  \\\n",
       "count       569.000000        569.000000      569.000000   569.000000   \n",
       "mean          0.096360          0.104341        0.088799     0.048919   \n",
       "std           0.014064          0.052813        0.079720     0.038803   \n",
       "min           0.052630          0.019380        0.000000     0.000000   \n",
       "25%           0.086370          0.064920        0.029560     0.020310   \n",
       "50%           0.095870          0.092630        0.061540     0.033500   \n",
       "75%           0.105300          0.130400        0.130700     0.074000   \n",
       "max           0.163400          0.345400        0.426800     0.201200   \n",
       "\n",
       "       symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "count     569.000000  ...    569.000000     569.000000       569.000000   \n",
       "mean        0.181162  ...     16.269190      25.677223       107.261213   \n",
       "std         0.027414  ...      4.833242       6.146258        33.602542   \n",
       "min         0.106000  ...      7.930000      12.020000        50.410000   \n",
       "25%         0.161900  ...     13.010000      21.080000        84.110000   \n",
       "50%         0.179200  ...     14.970000      25.410000        97.660000   \n",
       "75%         0.195700  ...     18.790000      29.720000       125.400000   \n",
       "max         0.304000  ...     36.040000      49.540000       251.200000   \n",
       "\n",
       "        area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "count   569.000000        569.000000         569.000000       569.000000   \n",
       "mean    880.583128          0.132369           0.254265         0.272188   \n",
       "std     569.356993          0.022832           0.157336         0.208624   \n",
       "min     185.200000          0.071170           0.027290         0.000000   \n",
       "25%     515.300000          0.116600           0.147200         0.114500   \n",
       "50%     686.500000          0.131300           0.211900         0.226700   \n",
       "75%    1084.000000          0.146000           0.339100         0.382900   \n",
       "max    4254.000000          0.222600           1.058000         1.252000   \n",
       "\n",
       "       points_worst  symmetry_worst  dimension_worst  \n",
       "count    569.000000      569.000000       569.000000  \n",
       "mean       0.114606        0.290076         0.083946  \n",
       "std        0.065732        0.061867         0.018061  \n",
       "min        0.000000        0.156500         0.055040  \n",
       "25%        0.064930        0.250400         0.071460  \n",
       "50%        0.099930        0.282200         0.080040  \n",
       "75%        0.161400        0.317900         0.092080  \n",
       "max        0.291000        0.663800         0.207500  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describing the values\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into input and output --> train and test \n",
    "# train--> Building the model\n",
    "# testing --> how well the model will work when it sees the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12.32</td>\n",
       "      <td>12.39</td>\n",
       "      <td>78.85</td>\n",
       "      <td>464.1</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>0.06981</td>\n",
       "      <td>0.03987</td>\n",
       "      <td>0.03700</td>\n",
       "      <td>0.1959</td>\n",
       "      <td>0.05955</td>\n",
       "      <td>...</td>\n",
       "      <td>13.50</td>\n",
       "      <td>15.64</td>\n",
       "      <td>86.97</td>\n",
       "      <td>549.1</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.12420</td>\n",
       "      <td>0.09391</td>\n",
       "      <td>0.2827</td>\n",
       "      <td>0.06771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10.60</td>\n",
       "      <td>18.95</td>\n",
       "      <td>69.28</td>\n",
       "      <td>346.4</td>\n",
       "      <td>0.09688</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>0.06387</td>\n",
       "      <td>0.02642</td>\n",
       "      <td>0.1922</td>\n",
       "      <td>0.06491</td>\n",
       "      <td>...</td>\n",
       "      <td>11.88</td>\n",
       "      <td>22.94</td>\n",
       "      <td>78.28</td>\n",
       "      <td>424.8</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.19160</td>\n",
       "      <td>0.07926</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.07587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11.04</td>\n",
       "      <td>16.83</td>\n",
       "      <td>70.92</td>\n",
       "      <td>373.2</td>\n",
       "      <td>0.10770</td>\n",
       "      <td>0.07804</td>\n",
       "      <td>0.03046</td>\n",
       "      <td>0.02480</td>\n",
       "      <td>0.1714</td>\n",
       "      <td>0.06340</td>\n",
       "      <td>...</td>\n",
       "      <td>12.41</td>\n",
       "      <td>26.44</td>\n",
       "      <td>79.93</td>\n",
       "      <td>471.4</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.10670</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.2998</td>\n",
       "      <td>0.07881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.28</td>\n",
       "      <td>13.39</td>\n",
       "      <td>73.00</td>\n",
       "      <td>384.8</td>\n",
       "      <td>0.11640</td>\n",
       "      <td>0.11360</td>\n",
       "      <td>0.04635</td>\n",
       "      <td>0.04796</td>\n",
       "      <td>0.1771</td>\n",
       "      <td>0.06072</td>\n",
       "      <td>...</td>\n",
       "      <td>11.92</td>\n",
       "      <td>15.77</td>\n",
       "      <td>76.53</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>0.1822</td>\n",
       "      <td>0.08669</td>\n",
       "      <td>0.08611</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.06784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>15.19</td>\n",
       "      <td>13.21</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.8</td>\n",
       "      <td>0.07963</td>\n",
       "      <td>0.06934</td>\n",
       "      <td>0.03393</td>\n",
       "      <td>0.02657</td>\n",
       "      <td>0.1721</td>\n",
       "      <td>0.05544</td>\n",
       "      <td>...</td>\n",
       "      <td>16.20</td>\n",
       "      <td>15.73</td>\n",
       "      <td>104.50</td>\n",
       "      <td>819.1</td>\n",
       "      <td>0.1126</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.13620</td>\n",
       "      <td>0.08178</td>\n",
       "      <td>0.2487</td>\n",
       "      <td>0.06766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0        12.32         12.39           78.85      464.1          0.10280   \n",
       "1        10.60         18.95           69.28      346.4          0.09688   \n",
       "2        11.04         16.83           70.92      373.2          0.10770   \n",
       "3        11.28         13.39           73.00      384.8          0.11640   \n",
       "4        15.19         13.21           97.65      711.8          0.07963   \n",
       "\n",
       "   compactness_mean  concavity_mean  points_mean  symmetry_mean  \\\n",
       "0           0.06981         0.03987      0.03700         0.1959   \n",
       "1           0.11470         0.06387      0.02642         0.1922   \n",
       "2           0.07804         0.03046      0.02480         0.1714   \n",
       "3           0.11360         0.04635      0.04796         0.1771   \n",
       "4           0.06934         0.03393      0.02657         0.1721   \n",
       "\n",
       "   dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.05955  ...         13.50          15.64            86.97   \n",
       "1         0.06491  ...         11.88          22.94            78.28   \n",
       "2         0.06340  ...         12.41          26.44            79.93   \n",
       "3         0.06072  ...         11.92          15.77            76.53   \n",
       "4         0.05544  ...         16.20          15.73           104.50   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0       549.1            0.1385             0.1266          0.12420   \n",
       "1       424.8            0.1213             0.2515          0.19160   \n",
       "2       471.4            0.1369             0.1482          0.10670   \n",
       "3       434.0            0.1367             0.1822          0.08669   \n",
       "4       819.1            0.1126             0.1737          0.13620   \n",
       "\n",
       "   points_worst  symmetry_worst  dimension_worst  \n",
       "0       0.09391          0.2827          0.06771  \n",
       "1       0.07926          0.2940          0.07587  \n",
       "2       0.07431          0.2998          0.07881  \n",
       "3       0.08611          0.2102          0.06784  \n",
       "4       0.08178          0.2487          0.06766  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepating the input values\n",
    "# drop the id and the input columns\n",
    "X=data.drop([\"id\",\"diagnosis\"],axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    B\n",
       "1    B\n",
       "2    B\n",
       "3    B\n",
       "4    B\n",
       "Name: diagnosis, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparing the output column which is the diagnosis\n",
    "y=data.diagnosis\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing training and testing data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing 70% of the total data into training \n",
    "# the remaining 30% as test data\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,\n",
    "                                               random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 30)\n",
      "(171, 30)\n",
      "(398,)\n",
      "(171,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0654828 , -1.35518629,  0.03134589, ..., -0.04689041,\n",
       "         0.3683001 , -1.22806684],\n",
       "       [-0.77639967, -0.1225787 , -0.77192193, ..., -0.39868555,\n",
       "         0.3648074 , -0.83648993],\n",
       "       [-0.84936282, -1.05782571, -0.87563499, ..., -1.03880764,\n",
       "        -1.65746674, -0.54459715],\n",
       "       ...,\n",
       "       [-0.88303812, -0.35998755, -0.85204535, ..., -0.1993652 ,\n",
       "        -0.98162901, -0.01313199],\n",
       "       [ 1.07854805,  0.213151  ,  0.91351698, ...,  0.10120204,\n",
       "         3.54665843, -1.20658794],\n",
       "       [-0.26846391, -0.90674734, -0.26149099, ..., -0.22037015,\n",
       "         1.74267813,  0.1823811 ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaled_X_train=scaler.fit_transform(X_train)\n",
    "scaled_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.767981</td>\n",
       "      <td>-0.055433</td>\n",
       "      <td>-0.795918</td>\n",
       "      <td>-0.721932</td>\n",
       "      <td>-0.589333</td>\n",
       "      <td>-0.996232</td>\n",
       "      <td>-0.780212</td>\n",
       "      <td>-0.661564</td>\n",
       "      <td>0.810759</td>\n",
       "      <td>-0.417646</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.785433</td>\n",
       "      <td>0.137175</td>\n",
       "      <td>-0.806874</td>\n",
       "      <td>-0.716765</td>\n",
       "      <td>-0.854530</td>\n",
       "      <td>-0.972772</td>\n",
       "      <td>-0.923478</td>\n",
       "      <td>-0.752143</td>\n",
       "      <td>0.726302</td>\n",
       "      <td>-0.720284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.116925</td>\n",
       "      <td>-0.731688</td>\n",
       "      <td>-0.158591</td>\n",
       "      <td>-0.209416</td>\n",
       "      <td>-0.875377</td>\n",
       "      <td>-0.728226</td>\n",
       "      <td>-0.760262</td>\n",
       "      <td>-0.697520</td>\n",
       "      <td>0.281483</td>\n",
       "      <td>-0.839423</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.273344</td>\n",
       "      <td>-0.865993</td>\n",
       "      <td>-0.216452</td>\n",
       "      <td>-0.348722</td>\n",
       "      <td>-0.911689</td>\n",
       "      <td>-0.222689</td>\n",
       "      <td>-0.624656</td>\n",
       "      <td>-0.633669</td>\n",
       "      <td>0.824098</td>\n",
       "      <td>-0.330910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.100998</td>\n",
       "      <td>-0.544639</td>\n",
       "      <td>1.047734</td>\n",
       "      <td>0.940735</td>\n",
       "      <td>-0.426476</td>\n",
       "      <td>0.438365</td>\n",
       "      <td>0.300001</td>\n",
       "      <td>0.371772</td>\n",
       "      <td>-0.289084</td>\n",
       "      <td>-0.675726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870599</td>\n",
       "      <td>-0.559798</td>\n",
       "      <td>0.797992</td>\n",
       "      <td>0.733636</td>\n",
       "      <td>-0.216988</td>\n",
       "      <td>0.157285</td>\n",
       "      <td>0.858626</td>\n",
       "      <td>0.630104</td>\n",
       "      <td>-0.015897</td>\n",
       "      <td>-0.042321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.922326</td>\n",
       "      <td>1.220340</td>\n",
       "      <td>-0.929322</td>\n",
       "      <td>-0.818221</td>\n",
       "      <td>-0.951934</td>\n",
       "      <td>-0.683493</td>\n",
       "      <td>-0.888348</td>\n",
       "      <td>-1.005166</td>\n",
       "      <td>0.671871</td>\n",
       "      <td>0.132434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.647087</td>\n",
       "      <td>1.035458</td>\n",
       "      <td>-0.669891</td>\n",
       "      <td>-0.636120</td>\n",
       "      <td>-0.476402</td>\n",
       "      <td>-0.531335</td>\n",
       "      <td>-0.990740</td>\n",
       "      <td>-1.196269</td>\n",
       "      <td>0.363061</td>\n",
       "      <td>-0.372215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.570612</td>\n",
       "      <td>-1.021855</td>\n",
       "      <td>0.510866</td>\n",
       "      <td>0.408905</td>\n",
       "      <td>-0.045084</td>\n",
       "      <td>-0.310914</td>\n",
       "      <td>-0.386171</td>\n",
       "      <td>-0.065263</td>\n",
       "      <td>-0.232778</td>\n",
       "      <td>-0.535625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319276</td>\n",
       "      <td>-0.972569</td>\n",
       "      <td>0.280965</td>\n",
       "      <td>0.134281</td>\n",
       "      <td>-0.467608</td>\n",
       "      <td>-0.472006</td>\n",
       "      <td>-0.138962</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>-0.127664</td>\n",
       "      <td>-0.710370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>-0.860588</td>\n",
       "      <td>-0.549435</td>\n",
       "      <td>-0.846758</td>\n",
       "      <td>-0.785752</td>\n",
       "      <td>0.842278</td>\n",
       "      <td>-0.447664</td>\n",
       "      <td>-0.697999</td>\n",
       "      <td>-0.583830</td>\n",
       "      <td>-0.311607</td>\n",
       "      <td>0.150131</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.775109</td>\n",
       "      <td>0.187925</td>\n",
       "      <td>-0.787857</td>\n",
       "      <td>-0.695690</td>\n",
       "      <td>0.249076</td>\n",
       "      <td>-0.631995</td>\n",
       "      <td>-0.765225</td>\n",
       "      <td>-0.566574</td>\n",
       "      <td>0.256534</td>\n",
       "      <td>-0.231776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>-0.086056</td>\n",
       "      <td>-0.798834</td>\n",
       "      <td>-0.053251</td>\n",
       "      <td>-0.195421</td>\n",
       "      <td>0.355099</td>\n",
       "      <td>0.532539</td>\n",
       "      <td>-0.095310</td>\n",
       "      <td>0.071722</td>\n",
       "      <td>-0.506801</td>\n",
       "      <td>0.483424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083880</td>\n",
       "      <td>-0.756033</td>\n",
       "      <td>0.114565</td>\n",
       "      <td>-0.101734</td>\n",
       "      <td>0.433744</td>\n",
       "      <td>0.741246</td>\n",
       "      <td>0.097336</td>\n",
       "      <td>0.400409</td>\n",
       "      <td>-0.457724</td>\n",
       "      <td>1.100466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>-0.647311</td>\n",
       "      <td>-0.446318</td>\n",
       "      <td>-0.670242</td>\n",
       "      <td>-0.621444</td>\n",
       "      <td>-0.329040</td>\n",
       "      <td>-0.756086</td>\n",
       "      <td>-0.722523</td>\n",
       "      <td>-0.797030</td>\n",
       "      <td>0.187639</td>\n",
       "      <td>-0.323262</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.560362</td>\n",
       "      <td>-0.141953</td>\n",
       "      <td>-0.607491</td>\n",
       "      <td>-0.537882</td>\n",
       "      <td>-0.300528</td>\n",
       "      <td>-0.469339</td>\n",
       "      <td>-0.572761</td>\n",
       "      <td>-0.880137</td>\n",
       "      <td>-0.125917</td>\n",
       "      <td>-0.099598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>2.144933</td>\n",
       "      <td>0.448162</td>\n",
       "      <td>2.259753</td>\n",
       "      <td>2.343085</td>\n",
       "      <td>-0.110505</td>\n",
       "      <td>1.868645</td>\n",
       "      <td>1.704113</td>\n",
       "      <td>1.543105</td>\n",
       "      <td>-0.285331</td>\n",
       "      <td>-0.065182</td>\n",
       "      <td>...</td>\n",
       "      <td>2.483269</td>\n",
       "      <td>0.482278</td>\n",
       "      <td>2.658104</td>\n",
       "      <td>2.635688</td>\n",
       "      <td>-0.177417</td>\n",
       "      <td>1.529859</td>\n",
       "      <td>1.622939</td>\n",
       "      <td>1.092515</td>\n",
       "      <td>-0.031614</td>\n",
       "      <td>0.306298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>-0.577154</td>\n",
       "      <td>0.863028</td>\n",
       "      <td>-0.528298</td>\n",
       "      <td>-0.576939</td>\n",
       "      <td>-1.826769</td>\n",
       "      <td>0.126410</td>\n",
       "      <td>-0.075742</td>\n",
       "      <td>-0.457733</td>\n",
       "      <td>-2.229763</td>\n",
       "      <td>0.620575</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.742071</td>\n",
       "      <td>0.571937</td>\n",
       "      <td>-0.567080</td>\n",
       "      <td>-0.666079</td>\n",
       "      <td>-1.901416</td>\n",
       "      <td>0.522594</td>\n",
       "      <td>0.164345</td>\n",
       "      <td>-0.039335</td>\n",
       "      <td>-1.152771</td>\n",
       "      <td>0.576712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0      -0.767981     -0.055433       -0.795918  -0.721932        -0.589333   \n",
       "1      -0.116925     -0.731688       -0.158591  -0.209416        -0.875377   \n",
       "2       1.100998     -0.544639        1.047734   0.940735        -0.426476   \n",
       "3      -0.922326      1.220340       -0.929322  -0.818221        -0.951934   \n",
       "4       0.570612     -1.021855        0.510866   0.408905        -0.045084   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "166    -0.860588     -0.549435       -0.846758  -0.785752         0.842278   \n",
       "167    -0.086056     -0.798834       -0.053251  -0.195421         0.355099   \n",
       "168    -0.647311     -0.446318       -0.670242  -0.621444        -0.329040   \n",
       "169     2.144933      0.448162        2.259753   2.343085        -0.110505   \n",
       "170    -0.577154      0.863028       -0.528298  -0.576939        -1.826769   \n",
       "\n",
       "     compactness_mean  concavity_mean  points_mean  symmetry_mean  \\\n",
       "0           -0.996232       -0.780212    -0.661564       0.810759   \n",
       "1           -0.728226       -0.760262    -0.697520       0.281483   \n",
       "2            0.438365        0.300001     0.371772      -0.289084   \n",
       "3           -0.683493       -0.888348    -1.005166       0.671871   \n",
       "4           -0.310914       -0.386171    -0.065263      -0.232778   \n",
       "..                ...             ...          ...            ...   \n",
       "166         -0.447664       -0.697999    -0.583830      -0.311607   \n",
       "167          0.532539       -0.095310     0.071722      -0.506801   \n",
       "168         -0.756086       -0.722523    -0.797030       0.187639   \n",
       "169          1.868645        1.704113     1.543105      -0.285331   \n",
       "170          0.126410       -0.075742    -0.457733      -2.229763   \n",
       "\n",
       "     dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         -0.417646  ...     -0.785433       0.137175        -0.806874   \n",
       "1         -0.839423  ...     -0.273344      -0.865993        -0.216452   \n",
       "2         -0.675726  ...      0.870599      -0.559798         0.797992   \n",
       "3          0.132434  ...     -0.647087       1.035458        -0.669891   \n",
       "4         -0.535625  ...      0.319276      -0.972569         0.280965   \n",
       "..              ...  ...           ...            ...              ...   \n",
       "166        0.150131  ...     -0.775109       0.187925        -0.787857   \n",
       "167        0.483424  ...      0.083880      -0.756033         0.114565   \n",
       "168       -0.323262  ...     -0.560362      -0.141953        -0.607491   \n",
       "169       -0.065182  ...      2.483269       0.482278         2.658104   \n",
       "170        0.620575  ...     -0.742071       0.571937        -0.567080   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0     -0.716765         -0.854530          -0.972772        -0.923478   \n",
       "1     -0.348722         -0.911689          -0.222689        -0.624656   \n",
       "2      0.733636         -0.216988           0.157285         0.858626   \n",
       "3     -0.636120         -0.476402          -0.531335        -0.990740   \n",
       "4      0.134281         -0.467608          -0.472006        -0.138962   \n",
       "..          ...               ...                ...              ...   \n",
       "166   -0.695690          0.249076          -0.631995        -0.765225   \n",
       "167   -0.101734          0.433744           0.741246         0.097336   \n",
       "168   -0.537882         -0.300528          -0.469339        -0.572761   \n",
       "169    2.635688         -0.177417           1.529859         1.622939   \n",
       "170   -0.666079         -1.901416           0.522594         0.164345   \n",
       "\n",
       "     points_worst  symmetry_worst  dimension_worst  \n",
       "0       -0.752143        0.726302        -0.720284  \n",
       "1       -0.633669        0.824098        -0.330910  \n",
       "2        0.630104       -0.015897        -0.042321  \n",
       "3       -1.196269        0.363061        -0.372215  \n",
       "4        0.016578       -0.127664        -0.710370  \n",
       "..            ...             ...              ...  \n",
       "166     -0.566574        0.256534        -0.231776  \n",
       "167      0.400409       -0.457724         1.100466  \n",
       "168     -0.880137       -0.125917        -0.099598  \n",
       "169      1.092515       -0.031614         0.306298  \n",
       "170     -0.039335       -1.152771         0.576712  \n",
       "\n",
       "[171 rows x 30 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# scaling for train data we use fit_transform \n",
    "# cuz in fit when it comes to the train it finds mean and variance\n",
    "# based on mean and variance it will apply it to the train data\n",
    "\n",
    "scaled_X_train=pd.DataFrame(scaler.fit_transform(X_train),\n",
    "                            columns=X_train.columns)\n",
    "scaled_X_train\n",
    "\n",
    "# scaling for test data and for test we should only use transform\n",
    "# cuz in fit when it comes to the train it finds mean and variance\n",
    "# based on mean and variance it will apply it to the train data\n",
    "\n",
    "scaled_X_test=pd.DataFrame(scaler.transform(X_test),\n",
    "                            columns=X_train.columns)\n",
    "scaled_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model building\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier(n_neighbors=3,metric=\"euclidean\")\n",
    "# applying on the the data set\n",
    "knn.fit(scaled_X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'M', 'B',\n",
       "       'M', 'B', 'M', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'M', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'M',\n",
       "       'M', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'B', 'M', 'B', 'B', 'M',\n",
       "       'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'B',\n",
       "       'M', 'B', 'B', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'M',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'M', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B',\n",
       "       'M', 'B', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'M',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'B', 'M', 'M',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'B',\n",
       "       'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'M', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'M', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M',\n",
       "       'M', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'M',\n",
       "       'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'M', 'B',\n",
       "       'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'M',\n",
       "       'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'B',\n",
       "       'M', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'B', 'B', 'B', 'B', 'M',\n",
       "       'B', 'B', 'M', 'M', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'B', 'M',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'B', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B', 'M', 'M', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'M', 'M', 'B',\n",
       "       'M', 'B', 'B', 'M', 'M', 'B', 'M', 'B'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions on the data\n",
    "# predict function\n",
    "# syntax objectname.predict(input)\n",
    "y_train_predict=knn.predict(scaled_X_train)\n",
    "y_train_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.98      1.00      0.99       257\n",
      "           M       1.00      0.96      0.98       141\n",
      "\n",
      "    accuracy                           0.99       398\n",
      "   macro avg       0.99      0.98      0.99       398\n",
      "weighted avg       0.99      0.99      0.99       398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking the accuracy\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train,y_train_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9181286549707602,\n",
       " 0.9473684210526315,\n",
       " 0.9590643274853801,\n",
       " 0.9415204678362573,\n",
       " 0.9590643274853801,\n",
       " 0.9590643274853801,\n",
       " 0.9649122807017544,\n",
       " 0.9532163742690059,\n",
       " 0.9590643274853801,\n",
       " 0.9532163742690059,\n",
       " 0.9532163742690059,\n",
       " 0.9415204678362573,\n",
       " 0.9473684210526315,\n",
       " 0.935672514619883,\n",
       " 0.9473684210526315,\n",
       " 0.9415204678362573,\n",
       " 0.9415204678362573,\n",
       " 0.9415204678362573,\n",
       " 0.9473684210526315]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "scores=[]\n",
    "# checking for optimum k value\n",
    "# building the model with multiple k values\n",
    "for k in range(1,20):\n",
    "    knn_model=KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_model.fit(scaled_X_train,y_train)\n",
    "    pred_test=knn_model.predict(scaled_X_test)\n",
    "    scores.append(accuracy_score(y_test,pred_test))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2240d5f0828>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot of kavlues and scores\n",
    "plt.plot(range(1,20),scores,marker='o',markerfacecolor=\"r\",linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimun k value is 7\n",
    "final_model=KNeighborsClassifier(n_neighbors=7,metric=\"euclidean\")\n",
    "final_model.fit(scaled_X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'M', 'B',\n",
       "       'M', 'B', 'M', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'M', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'M',\n",
       "       'M', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'B', 'M', 'B', 'B', 'M',\n",
       "       'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'B',\n",
       "       'M', 'B', 'B', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'M',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'M', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B',\n",
       "       'M', 'M', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'M',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'B', 'M', 'M',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'B',\n",
       "       'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'M', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'M', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M',\n",
       "       'M', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'M',\n",
       "       'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'M', 'B',\n",
       "       'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'M',\n",
       "       'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'B',\n",
       "       'M', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'B', 'B', 'B', 'B', 'M',\n",
       "       'B', 'B', 'M', 'M', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'B', 'M',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'B', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B', 'M', 'M', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'M', 'M', 'B',\n",
       "       'M', 'B', 'B', 'M', 'M', 'B', 'M', 'B'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting on the training data\n",
    "final_train_pred=final_model.predict(scaled_X_train)\n",
    "final_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2240d654160>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "sns.heatmap(confusion_matrix(y_train,final_train_pred),annot=True,fmt=\"d\",annot_kws={'size':20,\"ha\":\"center\",\"va\":\"center\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.97      1.00      0.99       257\n",
      "           M       1.00      0.95      0.97       141\n",
      "\n",
      "    accuracy                           0.98       398\n",
      "   macro avg       0.99      0.98      0.98       398\n",
      "weighted avg       0.98      0.98      0.98       398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report \n",
    "# prediction-->PPV-->out of the positive values,how many true positives are there\n",
    "print(classification_report(y_train,final_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'M',\n",
       "       'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'M',\n",
       "       'M', 'M', 'B', 'B', 'M', 'B', 'B', 'M', 'M', 'B', 'M', 'M', 'M',\n",
       "       'M', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'M',\n",
       "       'B', 'M', 'M', 'M', 'B', 'M', 'B', 'B', 'B', 'M', 'B', 'M', 'M',\n",
       "       'M', 'M', 'B', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'M', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'M', 'B', 'M',\n",
       "       'M', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'M',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B', 'B',\n",
       "       'M', 'M', 'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'M', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'M', 'B'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction on test data \n",
    "final_test_pred=final_model.predict(scaled_X_test)\n",
    "final_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2240d736e48>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD4CAYAAACt8i4nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPW0lEQVR4nO3dfbBcdX3H8fc39wbIgwiUJgZQMCXyYLFA0RFQdAwjlAcTq1So2IwEM1axwtgipa0U1IqtWqgFJaIQwRIzQiVlOlQaeRSLPKhVjEw0hhAMJBCeSeDe3W//yOqkJNy9l+xvz+7J+5U5s7tn9579/pH5zHe+53fORmYiSSpnXNUFSFLdGbSSVJhBK0mFGbSSVJhBK0mFDZb+gqFHlrusQZuZsNubqy5BPWj4+Qdja48xlswZv+v0rf6+0bCjlaTCine0ktRVzUbVFWzGoJVUL43hqivYjEErqVYym1WXsBmDVlK9NA1aSSrLjlaSCvNkmCQVZkcrSWWlqw4kqTBPhklSYY4OJKkwT4ZJUmF2tJJUmCfDJKkwT4ZJUlmZzmglqSxntJJUmKMDSSrMjlaSCmsMVV3BZgxaSfXi6ECSCnN0IEmF2dFKUmEGrSSVlZ4Mk6TCnNFKUmGODiSpMDtaSSrMjlaSCrOjlaTChr3xtySVZUcrSYU5o5WkwuxoJakwO1pJKsyOVpIKc9WBJBWWWXUFmxlXdQGS1FHN5ui3NiLijIi4NyJ+GhFXRcQOEbFLRNwQEctajzu3O45BK6leOhS0EbE78BfAIZn5+8AAcCJwFrAkM2cAS1qvR2TQSqqXbI5+a28QmBARg8BE4NfALGBB6/0FwOzRHESS6qPR6MhhMvPBiPgcsBJYD3wnM78TEVMzc3XrM6sjYkq7Y9nRSqqXMYwOImJeRNy1yTbvN4dpzV5nAa8GdgMmRcTJL6UkO1pJ9TKGCxYycz4w/0XePhL4VWauBYiIa4DDgIcjYlqrm50GrGn3PXa0kuqlczPalcAbI2JiRAQwE1gKLAbmtD4zB7i23YHsaCXVSjY7s442M++IiG8B9wDDwA/Z2P1OBhZFxFw2hvEJ7Y5l0Eqqlw7e6yAzzwHOecHu59jY3Y6aQSupXjq06qCTDFpJ9eLduySpMIN223HFom9z9eLryUze/Y6jed973snPly3nk//0RZ5dv4Hdpk3hs+ecyeRJk6ouVRX5yvzPc+wxR7Jm7SMceNCYRn4aiTeV2TYsW76Cqxdfz1WXXsDVCy7m5tt/wP0PPMg551/A6X/+fv79ii8x84jDuOwbV1ddqir09a8v4tjj3lt1GfXTwZvKdErboI2IfSPi4xHxLxFxYev5ft0orl8tX/EAr3vtvkzYYQcGBwc45MADWHLL7axYuYpDDjwAgENffzA33HxbxZWqSrfedgfrHnu86jLqp5mj37pkxKCNiI8DC4EAfgDc2Xp+VUS0vWPNtmrv6Xty949/yuNPPMn6DRu49ft38tDDa9l7+l7ceNv/APCdG2/loYcfqbhSqYYajdFvXdJuRjsXeG1mDm26MyK+ANwLnL+lP2pdLzwP4OLPf4pT/+ykDpTaP35vr1dxyntP4AOnn83ECRN4zd7TGRgY4JNnn8Fn/vlLfPmyf+Otb3oj48c7Ipc6LfvwZFiTjTdTuP8F+6e13tuiTa8fHnpkee9NprvgXccfxbuOPwqAC758Oa+YsivT93wlX7ngHwBYsXIVt9z+gypLlOqpiyOB0WoXtKcDSyJiGfBAa9+rgL2B00oW1u8efexxfmfnnVj90BqW3Pw9rrzkC7/d12w2uWTBQv5k9jFVlynVT7/9OGNmXh8RrwHeAOzOxvnsKuDOzOy9yy96yBlnf4rHn3ySwcFB/uZjH+LlO76MKxZ9m4XXXAfAkW85jHce+/aKq1SVrrziIt5yxKHsuusurFh+F+ee9zkuu3xh1WX1vx7saCMLrznbVkcHGtmE3d5cdQnqQcPPPxhbe4xnPnHiqDNn0nkLt/r7RsOzMZLqpd9GB5LUd3pwdGDQSqqVflzeJUn9xY5WkgozaCWpMG/8LUlldeo3wzrJoJVULwatJBXmqgNJKsyOVpIKM2glqaxsODqQpLLsaCWpLJd3SVJpBq0kFdZ7I1qDVlK95HDvJa1BK6leei9nDVpJ9eLJMEkqzY5Wksqyo5Wk0uxoJamsHK66gs0ZtJJqpQd/bZxxVRcgSR3VHMPWRkTsFBHfioifR8TSiDg0InaJiBsiYlnrced2xzFoJdVKNke/jcKFwPWZuS/wB8BS4CxgSWbOAJa0Xo/IoJVUK50K2ojYETgC+CpAZj6fmY8Ds4AFrY8tAGa3q8mglVQr2YhRbxExLyLu2mSbt8mhpgNrgcsi4ocRcWlETAKmZuZqgNbjlHY1eTJMUq2M5WRYZs4H5r/I24PAwcBHMvOOiLiQUYwJtsSOVlKtZDNGvbWxCliVmXe0Xn+LjcH7cERMA2g9rml3IINWUq10akabmQ8BD0TEPq1dM4GfAYuBOa19c4Br29Xk6EBSrWS27VTH4iPANyJiO2A58H42NqiLImIusBI4od1BDFpJtdLJCxYy80fAIVt4a+ZYjmPQSqqVZqOjHW1HGLSSamUUJ7m6zqCVVCsGrSQVlr13O1qDVlK92NFKUmEdXt7VEQatpFppuOpAksqyo5WkwpzRSlJhrjqQpMLsaCWpsEaz925KaNBKqhVHB5JUWNNVB5JUlsu7JKmwbXJ0MGWvt5f+CvWhR0/at+oSVFOODiSpMFcdSFJhPTg5MGgl1YujA0kqzFUHklRYB38Et2MMWkm1ktjRSlJRw44OJKksO1pJKswZrSQVZkcrSYXZ0UpSYQ07Wkkqqwd/ycaglVQvTTtaSSrLm8pIUmGeDJOkwprh6ECSimpUXcAW9N6tyCVpKzRj9NtoRMRARPwwIq5rvd4lIm6IiGWtx53bHcOglVQrTWLU2yh9FFi6yeuzgCWZOQNY0no9IoNWUq3kGLZ2ImIP4Fjg0k12zwIWtJ4vAGa3O45BK6lWxjI6iIh5EXHXJtu8FxzuAuBM/v9ihqmZuRqg9TilXU2eDJNUK2NZ3pWZ84H5W3ovIo4D1mTm3RHx1q2pyaCVVCuNzq3uOhx4R0QcA+wA7BgRVwIPR8S0zFwdEdOANe0O5OhAUq00x7CNJDP/OjP3yMy9gBOB72bmycBiYE7rY3OAa9vVZEcrqVa6cGXY+cCiiJgLrAROaPcHBq2kWinxk2GZeRNwU+v5o8DMsfy9QSupVrzXgSQV1ouX4Bq0kmrFG39LUmGODiSpMINWkgrzFxYkqTBntJJUmKsOJKmwZg8ODwxaSbXiyTBJKqz3+lmDVlLN2NFKUmHD0Xs9rUErqVZ6L2YNWkk14+hAkgpzeZckFdZ7MWvQSqoZRweSVFijB3tag1ZSrdjRSlJhaUcrSWXZ0W7DfnzvTTz99DM0Gg2Ghxu87Yh3Vl2SqjBxEhNP+UvG7b4XkKy/9HM0fvkztjtyNtsdORuaDYZ/dAcbFs2vutK+5fKubdzxx5zMukcfq7oMVWjCe09j6Cd3MvSv58LAIGy/PQP7Hsj4gw/j6b/9AAwPES/bqeoy+1rvxSyMq7oAaZuxw0QG9zmAoZv/c+PrxjA8+wzbzTyeDdcthOEhAPKpxysssv8Nk6PeusWOtksyk2uuvZzM5PKvXcWCy75ZdUnqsnFTptF86gkmnHomA6+aTmPFMtZfeREDU/dgcJ8D2OHdp8DQ82xYeAmNX91Xdbl9qxdPhr3kjjYi3j/Ce/Mi4q6IuOu5oSdf6lfUytFHvoe3vmkWJ/zxKZw672QOO/z1VZekLotxAwzsOYPnv7uYpz/xQfK5DWx/3IkwMEBMnMwz553Ghm9ewsQP/13Vpfa15hi2btma0cG5L/ZGZs7PzEMy85Dtx++4FV9RHw89tAaAR9au47r/uIGD//B1FVekbms+tpZct5bG8p8DMHTnLQzsOYPmurUM3X0bAI3l95GZxMteXmWpfS3H8K9bRgzaiPjfF9l+AkztUo19b+LECUyePOm3z9/2tjex9GfLKq5K3ZZPPEZz3VrGvWIPAAb3P4jmr+9n+J7vMbjfQQCMm7oHMTBIPvVElaX2tV7saNvNaKcCRwEvPFUewO1FKqqh352yK1dedTEAA4ODXL1oMUv++5aKq1IV1l/5RSZ88GxicDzNNat59tJ/hOc2MOHUv2Lypy+F4WGe/cpnqy6zrzWy92a07YL2OmByZv7ohW9ExE1FKqqh+1c8wJsPPb7qMtQDmit/yTN//6HN9q+/5DMVVFNPfbeONjPnjvDen3a+HEnaOr246sDlXZJqxUtwJamwvhsdSFK/6cXRgZfgSqqVRuaot5FExCsj4saIWBoR90bER1v7d4mIGyJiWetx53Y1GbSSaqVJjnprYxj4WGbuB7wR+HBE7A+cBSzJzBnAktbrERm0kmqlUxcsZObqzLyn9fwpYCmwOzALWND62AJgdruanNFKqpUSM9qI2As4CLgDmJqZq2FjGEfElHZ/b0crqVbGMjrY9AZYrW3eC48XEZOBq4HTM/Ml3SXLjlZSreQYLsHNzPnAi/6cRUSMZ2PIfiMzr2ntfjgiprW62WnAmnbfY0crqVYa5Ki3kUREAF8FlmbmFzZ5azEwp/V8DnBtu5rsaCXVSgcvWDgceB/wk4j4zf1ezgbOBxZFxFxgJXBCuwMZtJJqZSyjgzbHuY2NdyrckpljOZZBK6lWvARXkgrrxUtwDVpJtdKPN/6WpL7i6ECSCjNoJamwTq066CSDVlKt2NFKUmGuOpCkwhrZe78aZtBKqhVntJJUmDNaSSrMGa0kFdZ0dCBJZdnRSlJhrjqQpMIcHUhSYY4OJKkwO1pJKsyOVpIKa2Sj6hI2Y9BKqhUvwZWkwrwEV5IKs6OVpMJcdSBJhbnqQJIK8xJcSSrMGa0kFeaMVpIKs6OVpMJcRytJhdnRSlJhrjqQpMI8GSZJhTk6kKTCvDJMkgqzo5WkwnpxRhu9mP51FRHzMnN+1XWot/j/ov7GVV3ANmZe1QWoJ/n/ouYMWkkqzKCVpMIM2u5yDqct8f9FzXkyTJIKs6OVpMIMWkkqzKDtkog4OiLui4hfRMRZVdej6kXE1yJiTUT8tOpaVJZB2wURMQBcBPwRsD9wUkTsX21V6gGXA0dXXYTKM2i74w3ALzJzeWY+DywEZlVckyqWmbcA66quQ+UZtN2xO/DAJq9XtfZJ2gYYtN0RW9jnujppG2HQdscq4JWbvN4D+HVFtUjqMoO2O+4EZkTEqyNiO+BEYHHFNUnqEoO2CzJzGDgN+C9gKbAoM++ttipVLSKuAr4P7BMRqyJibtU1qQwvwZWkwuxoJakwg1aSCjNoJakwg1aSCjNoJakwg1aSCjNoJamw/wPL4aOJ5IOX6wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "sns.heatmap(confusion_matrix(y_test,final_test_pred),annot=True,fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.95      0.99      0.97       100\n",
      "           M       0.99      0.93      0.96        71\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.97      0.96      0.96       171\n",
      "weighted avg       0.97      0.96      0.96       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classificaton report for test data \n",
    "print(classification_report(y_test,final_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 33(01-07-2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1\n",
       "0    1.000000  0.000000\n",
       "1    1.000000  0.000000\n",
       "2    0.142857  0.857143\n",
       "3    1.000000  0.000000\n",
       "4    1.000000  0.000000\n",
       "..        ...       ...\n",
       "166  1.000000  0.000000\n",
       "167  0.857143  0.142857\n",
       "168  1.000000  0.000000\n",
       "169  0.000000  1.000000\n",
       "170  1.000000  0.000000\n",
       "\n",
       "[171 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict the probability of a tumor being B,M\n",
    "#Predict-> give you the pre3dicted values(B,M)\n",
    "#predict_proba-> gives you the probability associated with B and probability associates with M\n",
    "y_test_prob=final_model.predict_proba(scaled_X_test)\n",
    "y_test_prob=pd.DataFrame(y_test_prob)\n",
    "y_test_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "m_prob=final_model.predict_proba(scaled_X_test)[:,1]\n",
    "fpr,tpr,threshold=roc_curve(y_test,m_prob,pos_label='M')\n",
    "#True positive rates->tpr\n",
    "#False positive rates-> Fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.74647887, 0.88732394, 0.92957746, 0.95774648,\n",
       "       0.95774648, 0.98591549, 1.        ])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2240d612240>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9854929577464789"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,m_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold:\n",
    " - Genreally random_state=0,1,2,3,4,5,... takes n different combinations of the data  in the ratio of test and train data splitting\n",
    " - So for KFold, we take for ex:5 combinations and KFold will return the indices of the records which are splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5 folds -> in each and every fold-> create a partof test data and remaining\n",
    "from sklearn.model_selection import KFold\n",
    "kfold=KFold(n_splits=5)\n",
    "kfold.get_n_splits(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9122807017543859, 0.9035087719298246, 0.956140350877193, 0.9473684210526315, 0.9469026548672567]\n",
      "Average score of the model: 0.9332401800962584\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model_knn=KNeighborsClassifier(n_neighbors=7,metric='euclidean')\n",
    "#model will build for 5 times->for loop\n",
    "#some set of indices will be in test data and he remaining set of indices will be in training data\n",
    "#in each and every fold, it is splitting training and testing data\n",
    "\n",
    "score=[]\n",
    "for train_index, test_index in kfold.split(X,y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    #Using iloc to access the inidices of the selected data splits\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    #pass the X_train,_train into the knn algorithm\n",
    "    model_knn.fit(X_train,y_train)\n",
    "    \n",
    "    #Predict the model on test data(X_test,y_test)\n",
    "    y_pred_test = model_knn.predict(X_test)\n",
    "    \n",
    "    #Accuracy score of y_pred_test and actual values(y_test)\n",
    "    accuracy = accuracy_score(y_test,y_pred_test)\n",
    "    #Runs for 5 times , 5 models will be built , 5 accuracies are made.\n",
    "    score.append(accuracy)\n",
    "print(score)\n",
    "print('Average score of the model:' ,np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
